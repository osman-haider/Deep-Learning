{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPYRFeaUuMLctcj1qpwHr4g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"VEPnj03hyHR2","executionInfo":{"status":"ok","timestamp":1732277489609,"user_tz":-300,"elapsed":352,"user":{"displayName":"osman haider","userId":"15157778702259941908"}},"outputId":"cd624551-d4fc-4318-fd44-d81603289a11","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Output: [0.80533842 0.92689883]\n"]}],"source":["import numpy as np\n","\n","# Initialize weights and biases\n","weights_input_hidden = np.array([[0.1, 0.2], [0.3, 0.4]])  # 2 inputs -> 2 hidden neurons\n","bias_hidden = np.array([0.1, 0.2])  # Bias for hidden neurons\n","weights_hidden_output = np.array([0.5, 0.6])  # 2 hidden neurons -> 1 output neuron\n","bias_output = 0.3  # Bias for output neuron\n","\n","# Activation function (ReLU for hidden, sigmoid for output)\n","def relu(z):\n","    return np.maximum(0, z)\n","\n","def sigmoid(z):\n","    return 1 / (1 + np.exp(-z))\n","\n","# Input data\n","X = np.array([[1, 2], [3, 4]])  # 2 samples, 2 features each\n","\n","# Step 1: Compute hidden layer activations\n","z_hidden = np.dot(X, weights_input_hidden) + bias_hidden  # Weighted sum\n","a_hidden = relu(z_hidden)  # Apply ReLU\n","\n","# Step 2: Compute output layer activations\n","z_output = np.dot(a_hidden, weights_hidden_output) + bias_output  # Weighted sum\n","a_output = sigmoid(z_output)  # Apply sigmoid\n","\n","print(\"Output:\", a_output)"]},{"cell_type":"markdown","source":["# Example: Backpropagation Step-by-Step"],"metadata":{"id":"Bptjhlv38Sd6"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Input data (2 samples, 2 features each)\n","X = np.array([[1, 2], [2, 3]])\n","y = np.array([[1], [0]])  # True labels\n","\n","# Initialize weights and biases randomly\n","np.random.seed(42)\n","W1 = np.random.rand(2, 2)  # 2 inputs -> 2 hidden neurons\n","b1 = np.random.rand(1, 2)  # Bias for hidden layer\n","W2 = np.random.rand(2, 1)  # 2 hidden neurons -> 1 output neuron\n","b2 = np.random.rand(1, 1)  # Bias for output layer\n","\n","# Activation functions and their derivatives\n","def sigmoid(z):\n","    return 1 / (1 + np.exp(-z))\n","\n","def sigmoid_derivative(a):\n","    return a * (1 - a)"],"metadata":{"id":"fS3pEZIqyKIq","executionInfo":{"status":"ok","timestamp":1732280150101,"user_tz":-300,"elapsed":327,"user":{"displayName":"osman haider","userId":"15157778702259941908"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["W1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6yQBqu-58WTt","executionInfo":{"status":"ok","timestamp":1732280159188,"user_tz":-300,"elapsed":20,"user":{"displayName":"osman haider","userId":"15157778702259941908"}},"outputId":"b3931af6-bd07-480f-d415-7318bc353322"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.37454012, 0.95071431],\n","       [0.73199394, 0.59865848]])"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["## Step 2: Forward Propagation"],"metadata":{"id":"dIfjc9Gl8c6_"}},{"cell_type":"code","source":["# Forward pass\n","# Hidden layer computations\n","z1 = np.dot(X, W1) + b1  # Weighted sum\n","a1 = sigmoid(z1)          # Apply sigmoid activation\n","\n","# Output layer computations\n","z2 = np.dot(a1, W2) + b2  # Weighted sum\n","a2 = sigmoid(z2)          # Final output (predicted value)\n","\n","# Compute the loss (Binary Cross-Entropy Loss)\n","loss = -np.mean(y * np.log(a2) + (1 - y) * np.log(1 - a2))\n","print(\"Loss:\", loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oak5YejF8YS9","executionInfo":{"status":"ok","timestamp":1732280192817,"user_tz":-300,"elapsed":358,"user":{"displayName":"osman haider","userId":"15157778702259941908"}},"outputId":"a56cbee1-5e74-423a-8bd2-9dae1d7c5216"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss: 0.9590413360683729\n"]}]},{"cell_type":"markdown","source":["## Step 3: Backward Propagation"],"metadata":{"id":"YQvNAr9Q8mFi"}},{"cell_type":"code","source":["# Backward pass\n","# Output layer gradients\n","delta2 = a2 - y\n","dW2 = np.dot(a1.T, delta2)\n","db2 = np.sum(delta2, axis=0, keepdims=True)\n","\n","# Hidden layer gradients\n","delta1 = np.dot(delta2, W2.T) * sigmoid_derivative(a1)\n","dW1 = np.dot(X.T, delta1)\n","db1 = np.sum(delta1, axis=0, keepdims=True)\n","\n","# Print gradients\n","print(\"Gradient dW2:\", dW2)\n","print(\"Gradient db2:\", db2)\n","print(\"Gradient dW1:\", dW1)\n","print(\"Gradient db1:\", db1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5sIZP4_F8gum","executionInfo":{"status":"ok","timestamp":1732280240977,"user_tz":-300,"elapsed":376,"user":{"displayName":"osman haider","userId":"15157778702259941908"}},"outputId":"b578d0d4-5a7b-4211-f3e0-74a257ecb096"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Gradient dW2: [[0.6144307 ]\n"," [0.62712197]]\n","Gradient db2: [[0.6267222]]\n","Gradient dW1: [[0.00274407 0.01512979]\n"," [0.0035295  0.01584567]]\n","Gradient db1: [[0.00078544 0.00071587]]\n"]}]},{"cell_type":"markdown","source":["## Step 4: Update Weights and Biases"],"metadata":{"id":"74lyeOCX8wPQ"}},{"cell_type":"code","source":["# Learning rate\n","learning_rate = 0.1\n","\n","# Update weights and biases\n","W1 -= learning_rate * dW1\n","b1 -= learning_rate * db1\n","W2 -= learning_rate * dW2\n","b2 -= learning_rate * db2\n","\n","print(\"Updated W1:\", W1)\n","print(\"Updated b1:\", b1)\n","print(\"Updated W2:\", W2)\n","print(\"Updated b2:\", b2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_CnoUL268sZ2","executionInfo":{"status":"ok","timestamp":1732280273228,"user_tz":-300,"elapsed":342,"user":{"displayName":"osman haider","userId":"15157778702259941908"}},"outputId":"692684d8-387d-42e3-ad8b-3284bcdb6333"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Updated W1: [[0.37426571 0.94920133]\n"," [0.73164099 0.59707392]]\n","Updated b1: [[0.1559401  0.15592293]]\n","Updated W2: [[-0.00335946]\n"," [ 0.80346395]]\n","Updated b2: [[0.53844279]]\n"]}]},{"cell_type":"markdown","source":["## Iterative Training"],"metadata":{"id":"rxCUsLM785jn"}},{"cell_type":"code","source":["for epoch in range(1000):\n","    # Forward pass\n","    z1 = np.dot(X, W1) + b1\n","    a1 = sigmoid(z1)\n","    z2 = np.dot(a1, W2) + b2\n","    a2 = sigmoid(z2)\n","    loss = -np.mean(y * np.log(a2) + (1 - y) * np.log(1 - a2))\n","\n","    # Backward pass\n","    delta2 = a2 - y\n","    dW2 = np.dot(a1.T, delta2)\n","    db2 = np.sum(delta2, axis=0, keepdims=True)\n","    delta1 = np.dot(delta2, W2.T) * sigmoid_derivative(a1)\n","    dW1 = np.dot(X.T, delta1)\n","    db1 = np.sum(delta1, axis=0, keepdims=True)\n","\n","    # Update parameters\n","    W1 -= learning_rate * dW1\n","    b1 -= learning_rate * db1\n","    W2 -= learning_rate * dW2\n","    b2 -= learning_rate * db2\n","\n","    if epoch % 100 == 0:\n","        print(f\"Epoch {epoch}, Loss: {loss}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mmkuy5Gz80Xi","executionInfo":{"status":"ok","timestamp":1732280306118,"user_tz":-300,"elapsed":669,"user":{"displayName":"osman haider","userId":"15157778702259941908"}},"outputId":"6aae9614-82c2-4b42-8d06-e1aacef64994"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss: 0.903348793298792\n","Epoch 100, Loss: 0.6785156101299639\n","Epoch 200, Loss: 0.6558760710323448\n","Epoch 300, Loss: 0.6005594228611344\n","Epoch 400, Loss: 0.4793240909116128\n","Epoch 500, Loss: 0.322165987070469\n","Epoch 600, Loss: 0.20531123826507064\n","Epoch 700, Loss: 0.1379114421875627\n","Epoch 800, Loss: 0.09950109101359064\n","Epoch 900, Loss: 0.07616360712960568\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"_QqEG68i88QN"},"execution_count":null,"outputs":[]}]}