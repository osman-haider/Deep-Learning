{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPEFMjxSoVgpzoV4kiZ/rS+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"005lcbujiAUk","executionInfo":{"status":"ok","timestamp":1733078588788,"user_tz":-300,"elapsed":10836,"user":{"displayName":"osman haider","userId":"15157778702259941908"}}},"outputs":[],"source":["import numpy as np\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense, Attention"]},{"cell_type":"code","source":["# Input sequences (numbers)\n","input_texts = [\"123\", \"456\", \"789\"]\n","\n","# Output sequences (words)\n","target_texts = [\"one two three\", \"four five six\", \"seven eight nine\"]\n","\n","# Create vocabularies for input and output\n","input_vocab = sorted(set(\"\".join(input_texts)))  # Characters: ['1', '2', ..., '9']\n","output_vocab = sorted(set(\" \".join(target_texts)))  # Words: ['e', 'f', ..., 'v', 'x']\n","\n","# Map each character/word to an index\n","input_token_index = {char: i for i, char in enumerate(input_vocab)}\n","output_token_index = {char: i for i, char in enumerate(output_vocab)}\n","reverse_output_token_index = {i: char for char, i in output_token_index.items()}\n","\n","# Maximum sequence lengths\n","max_encoder_seq_length = max(len(text) for text in input_texts)\n","max_decoder_seq_length = max(len(text) for text in target_texts)\n","\n","# Number of unique tokens\n","num_encoder_tokens = len(input_vocab)\n","num_decoder_tokens = len(output_vocab)\n","\n","# One-hot encode input and target sequences\n","encoder_input_data = np.zeros(\n","    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",")\n","decoder_input_data = np.zeros(\n","    (len(target_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",")\n","decoder_target_data = np.zeros(\n","    (len(target_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",")\n","\n","# Fill the one-hot encoded arrays\n","for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n","    for t, char in enumerate(input_text):\n","        encoder_input_data[i, t, input_token_index[char]] = 1.0\n","    for t, char in enumerate(target_text):\n","        decoder_input_data[i, t, output_token_index[char]] = 1.0\n","        if t > 0:\n","            decoder_target_data[i, t - 1, output_token_index[char]] = 1.0"],"metadata":{"id":"zPxfu5haiEbO","executionInfo":{"status":"ok","timestamp":1733078588789,"user_tz":-300,"elapsed":4,"user":{"displayName":"osman haider","userId":"15157778702259941908"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Build the Encoder-Decoder Model with Attention"],"metadata":{"id":"MsFVNpXyiKNp"}},{"cell_type":"code","source":["# Encoder\n","encoder_inputs = Input(shape=(None, num_encoder_tokens))  # Input shape: (sequence_length, num_encoder_tokens)\n","encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n","encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)  # Hidden states for attention\n","\n","# Decoder\n","decoder_inputs = Input(shape=(None, num_decoder_tokens))  # Input shape: (sequence_length, num_decoder_tokens)\n","decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=[state_h, state_c])\n","\n","# Attention layer\n","attention = Attention()\n","context_vector = attention([decoder_outputs, encoder_outputs])\n","\n","# Concatenate context vector with decoder LSTM output\n","decoder_combined_context = Dense(256, activation=\"tanh\")(context_vector)\n","\n","# Final output layer (softmax activation for probabilities)\n","decoder_dense = Dense(num_decoder_tokens, activation=\"softmax\")\n","decoder_outputs = decoder_dense(decoder_combined_context)\n","\n","# Full model\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"id":"o4fqv--qiGYY","executionInfo":{"status":"ok","timestamp":1733078602501,"user_tz":-300,"elapsed":712,"user":{"displayName":"osman haider","userId":"15157778702259941908"}},"outputId":"89038689-1ff6-4fd0-ed1d-a864541ce2fb"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"functional\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ lstm (\u001b[38;5;33mLSTM\u001b[0m)               │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),    │        \u001b[38;5;34m272,384\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │                        │\n","│                           │ \u001b[38;5;34m256\u001b[0m)]                  │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),    │        \u001b[38;5;34m278,528\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n","│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m], lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m] │\n","│                           │ \u001b[38;5;34m256\u001b[0m)]                  │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ attention (\u001b[38;5;33mAttention\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n","│                           │                        │                │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m65,792\u001b[0m │ attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)       │          \u001b[38;5;34m3,855\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">272,384</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │                        │\n","│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                  │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">278,528</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n","│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>], lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>] │\n","│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                  │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n","│                           │                        │                │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,855</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m620,559\u001b[0m (2.37 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">620,559</span> (2.37 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m620,559\u001b[0m (2.37 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">620,559</span> (2.37 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["## Train the Model"],"metadata":{"id":"1pD6mZmfiUBB"}},{"cell_type":"code","source":["model.fit(\n","    [encoder_input_data, decoder_input_data],  # Input sequences and target sequences\n","    decoder_target_data,                       # Target sequence shifted by one time step\n","    batch_size=64,\n","    epochs=50,\n","    validation_split=0.2,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zLwAjgnWiM39","executionInfo":{"status":"ok","timestamp":1733078650196,"user_tz":-300,"elapsed":11446,"user":{"displayName":"osman haider","userId":"15157778702259941908"}},"outputId":"c35f3715-23c4-4a2f-92f8-7d3f3753a7d0"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.2500 - loss: 2.0269 - val_accuracy: 0.1875 - val_loss: 2.5286\n","Epoch 2/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.2812 - loss: 2.0142 - val_accuracy: 0.1875 - val_loss: 2.5230\n","Epoch 3/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.2812 - loss: 2.0013 - val_accuracy: 0.1875 - val_loss: 2.5172\n","Epoch 4/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.2812 - loss: 1.9880 - val_accuracy: 0.1875 - val_loss: 2.5111\n","Epoch 5/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.2812 - loss: 1.9740 - val_accuracy: 0.1875 - val_loss: 2.5043\n","Epoch 6/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.2812 - loss: 1.9591 - val_accuracy: 0.1875 - val_loss: 2.4970\n","Epoch 7/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.2812 - loss: 1.9432 - val_accuracy: 0.1875 - val_loss: 2.4888\n","Epoch 8/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.2812 - loss: 1.9261 - val_accuracy: 0.1875 - val_loss: 2.4799\n","Epoch 9/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.2812 - loss: 1.9077 - val_accuracy: 0.1875 - val_loss: 2.4700\n","Epoch 10/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.2812 - loss: 1.8881 - val_accuracy: 0.1875 - val_loss: 2.4594\n","Epoch 11/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.2812 - loss: 1.8672 - val_accuracy: 0.1875 - val_loss: 2.4479\n","Epoch 12/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.2812 - loss: 1.8454 - val_accuracy: 0.1875 - val_loss: 2.4359\n","Epoch 13/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.2812 - loss: 1.8229 - val_accuracy: 0.1875 - val_loss: 2.4235\n","Epoch 14/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.2812 - loss: 1.8004 - val_accuracy: 0.1875 - val_loss: 2.4115\n","Epoch 15/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.2812 - loss: 1.7784 - val_accuracy: 0.1875 - val_loss: 2.4004\n","Epoch 16/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.2812 - loss: 1.7580 - val_accuracy: 0.1875 - val_loss: 2.3918\n","Epoch 17/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.2812 - loss: 1.7406 - val_accuracy: 0.1875 - val_loss: 2.3873\n","Epoch 18/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.2812 - loss: 1.7268 - val_accuracy: 0.1875 - val_loss: 2.3877\n","Epoch 19/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.2812 - loss: 1.7135 - val_accuracy: 0.1875 - val_loss: 2.3921\n","Epoch 20/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.2812 - loss: 1.6998 - val_accuracy: 0.1875 - val_loss: 2.3991\n","Epoch 21/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.2812 - loss: 1.6870 - val_accuracy: 0.1875 - val_loss: 2.4071\n","Epoch 22/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.1562 - loss: 1.6763 - val_accuracy: 0.1875 - val_loss: 2.4150\n","Epoch 23/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.1562 - loss: 1.6676 - val_accuracy: 0.1875 - val_loss: 2.4219\n","Epoch 24/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.1562 - loss: 1.6598 - val_accuracy: 0.1875 - val_loss: 2.4276\n","Epoch 25/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.1562 - loss: 1.6521 - val_accuracy: 0.1875 - val_loss: 2.4324\n","Epoch 26/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.1562 - loss: 1.6446 - val_accuracy: 0.1875 - val_loss: 2.4367\n","Epoch 27/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.2812 - loss: 1.6380 - val_accuracy: 0.1875 - val_loss: 2.4410\n","Epoch 28/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.2812 - loss: 1.6333 - val_accuracy: 0.1875 - val_loss: 2.4463\n","Epoch 29/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.2812 - loss: 1.6314 - val_accuracy: 0.1875 - val_loss: 2.4534\n","Epoch 30/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.2812 - loss: 1.6321 - val_accuracy: 0.1875 - val_loss: 2.4625\n","Epoch 31/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.2812 - loss: 1.6338 - val_accuracy: 0.2500 - val_loss: 2.4733\n","Epoch 32/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.2812 - loss: 1.6347 - val_accuracy: 0.2500 - val_loss: 2.4845\n","Epoch 33/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.2812 - loss: 1.6340 - val_accuracy: 0.2500 - val_loss: 2.4943\n","Epoch 34/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.2812 - loss: 1.6322 - val_accuracy: 0.1250 - val_loss: 2.5012\n","Epoch 35/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.2812 - loss: 1.6305 - val_accuracy: 0.1875 - val_loss: 2.5035\n","Epoch 36/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.1562 - loss: 1.6307 - val_accuracy: 0.1875 - val_loss: 2.5001\n","Epoch 37/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.1562 - loss: 1.6341 - val_accuracy: 0.1875 - val_loss: 2.4919\n","Epoch 38/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.1562 - loss: 1.6418 - val_accuracy: 0.1875 - val_loss: 2.4823\n","Epoch 39/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.1562 - loss: 1.6538 - val_accuracy: 0.1875 - val_loss: 2.4726\n","Epoch 40/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.2500 - loss: 1.6689 - val_accuracy: 0.1875 - val_loss: 2.4639\n","Epoch 41/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.3750 - loss: 1.6849 - val_accuracy: 0.1875 - val_loss: 2.4581\n","Epoch 42/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.3750 - loss: 1.6998 - val_accuracy: 0.1875 - val_loss: 2.4576\n","Epoch 43/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.3750 - loss: 1.7119 - val_accuracy: 0.2500 - val_loss: 2.4629\n","Epoch 44/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.3750 - loss: 1.7214 - val_accuracy: 0.2500 - val_loss: 2.4725\n","Epoch 45/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.3750 - loss: 1.7292 - val_accuracy: 0.2500 - val_loss: 2.4822\n","Epoch 46/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.2812 - loss: 1.7357 - val_accuracy: 0.2500 - val_loss: 2.4881\n","Epoch 47/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.2812 - loss: 1.7402 - val_accuracy: 0.2500 - val_loss: 2.4877\n","Epoch 48/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.2812 - loss: 1.7422 - val_accuracy: 0.2500 - val_loss: 2.4814\n","Epoch 49/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.2812 - loss: 1.7418 - val_accuracy: 0.2500 - val_loss: 2.4717\n","Epoch 50/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.2812 - loss: 1.7403 - val_accuracy: 0.2500 - val_loss: 2.4624\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x792aa8bcec20>"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["## Create Inference Models for Prediction"],"metadata":{"id":"qKh0XJD-iZq5"}},{"cell_type":"code","source":["# Encoder Model\n","encoder_model = Model(encoder_inputs, [encoder_outputs, state_h, state_c])\n","\n","# Decoder Model\n","decoder_state_input_h = Input(shape=(256,))\n","decoder_state_input_c = Input(shape=(256,))\n","decoder_hidden_states_input = Input(shape=(None, 256))\n","\n","decoder_outputs, state_h, state_c = decoder_lstm(\n","    decoder_inputs, initial_state=[decoder_state_input_h, decoder_state_input_c]\n",")\n","context_vector = attention([decoder_outputs, decoder_hidden_states_input])\n","decoder_combined_context = Dense(256, activation=\"tanh\")(context_vector)\n","decoder_outputs = decoder_dense(decoder_combined_context)\n","\n","decoder_model = Model(\n","    [decoder_inputs, decoder_hidden_states_input, decoder_state_input_h, decoder_state_input_c],\n","    [decoder_outputs, state_h, state_c],\n",")"],"metadata":{"id":"us5SwosHiV5k","executionInfo":{"status":"ok","timestamp":1733078661902,"user_tz":-300,"elapsed":355,"user":{"displayName":"osman haider","userId":"15157778702259941908"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Predict the Output Sequence"],"metadata":{"id":"loH4Zb4Uid0K"}},{"cell_type":"code","source":["def decode_sequence(input_seq):\n","    # Encode the input sequence\n","    encoder_outputs, state_h, state_c = encoder_model.predict(input_seq)\n","\n","    # Start the target sequence with the \"start\" token\n","    target_seq = np.zeros((1, 1, num_decoder_tokens))\n","    target_seq[0, 0, output_token_index[\" \"]] = 1.0  # Assume \" \" is the start token\n","\n","    decoded_sentence = \"\"\n","    stop_condition = False\n","\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict(\n","            [target_seq, encoder_outputs, state_h, state_c]\n","        )\n","\n","        # Get the most likely token\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_char = reverse_output_token_index[sampled_token_index]\n","        decoded_sentence += sampled_char\n","\n","        # Stop if end token is reached or max length is exceeded\n","        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n","            stop_condition = True\n","\n","        # Update target sequence and states\n","        target_seq = np.zeros((1, 1, num_decoder_tokens))\n","        target_seq[0, 0, sampled_token_index] = 1.0\n","        state_h, state_c = h, c\n","\n","    return decoded_sentence"],"metadata":{"id":"YVe0rXY9ibdy","executionInfo":{"status":"ok","timestamp":1733078678939,"user_tz":-300,"elapsed":337,"user":{"displayName":"osman haider","userId":"15157778702259941908"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Test the Model"],"metadata":{"id":"6uRXTE-rih0I"}},{"cell_type":"code","source":["# Test input sequence\n","test_input = \"123\"\n","input_seq = np.zeros((1, max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\")\n","for t, char in enumerate(test_input):\n","    input_seq[0, t, input_token_index[char]] = 1.0\n","\n","# Decode the sequence\n","decoded_sentence = decode_sequence(input_seq)\n","print(f\"Input: {test_input}\")\n","print(f\"Output: {decoded_sentence}\")"],"metadata":{"id":"A1KY64QUifoL","executionInfo":{"status":"ok","timestamp":1733078697421,"user_tz":-300,"elapsed":2514,"user":{"displayName":"osman haider","userId":"15157778702259941908"}},"outputId":"7f98725f-3fdc-4d02-9030-c99983cfb6b2","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","Input: 123\n","Output: wwwwwwwwwwwwwwwww\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ODrZBTGBijkj"},"execution_count":null,"outputs":[]}]}